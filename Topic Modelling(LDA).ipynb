{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cfaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01e9e478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Clean_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment Label</th>\n",
       "      <th>Churn_Keyword</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Review_Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trying to buy broadband through Uswitch, then ...</td>\n",
       "      <td>Alfie Calas</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 22:03:24+00:00</td>\n",
       "      <td>trying to buy broadband through uswitch then h...</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>22:03:24</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>280</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Sona did a great job either my trade in and co...</td>\n",
       "      <td>Julliette</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 21:51:17+00:00</td>\n",
       "      <td>sona did a great job either my trade in and co...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>21:51:17</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>One of the worst , if not the worst when it co...</td>\n",
       "      <td>Vlad Ureche</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 21:28:36+00:00</td>\n",
       "      <td>one of the worst if not the worst when it come...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>21:28:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>154</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>How those people get 4.6 rate that’s a joke my...</td>\n",
       "      <td>Adam Farbotko</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 21:14:08+00:00</td>\n",
       "      <td>how those people get rate thats a joke my full...</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>21:14:08</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>240</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Held to ransom by a ‘reputable’ company. Purch...</td>\n",
       "      <td>Chloe</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 20:24:59+00:00</td>\n",
       "      <td>held to ransom by a reputable company purchase...</td>\n",
       "      <td>-0.003634</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>20:24:59</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>1620</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                             Review           Name  \\\n",
       "0       1  Trying to buy broadband through Uswitch, then ...    Alfie Calas   \n",
       "1       5  Sona did a great job either my trade in and co...      Julliette   \n",
       "2       1  One of the worst , if not the worst when it co...    Vlad Ureche   \n",
       "3       1  How those people get 4.6 rate that’s a joke my...  Adam Farbotko   \n",
       "4       1  Held to ransom by a ‘reputable’ company. Purch...          Chloe   \n",
       "\n",
       "  Location                       Date  \\\n",
       "0       GB  2025-06-05 22:03:24+00:00   \n",
       "1       GB  2025-06-05 21:51:17+00:00   \n",
       "2       GB  2025-06-05 21:28:36+00:00   \n",
       "3       GB  2025-06-05 21:14:08+00:00   \n",
       "4       GB  2025-06-05 20:24:59+00:00   \n",
       "\n",
       "                                        Clean_Review  Sentiment  \\\n",
       "0  trying to buy broadband through uswitch then h...  -0.020000   \n",
       "1  sona did a great job either my trade in and co...   0.700000   \n",
       "2  one of the worst if not the worst when it come...  -0.200000   \n",
       "3  how those people get rate thats a joke my full...   0.275000   \n",
       "4  held to ransom by a reputable company purchase...  -0.003634   \n",
       "\n",
       "  Sentiment Label  Churn_Keyword  Churn Review_Date Review_Time   Weekday  \\\n",
       "0         neutral              1      1  2025-06-05    22:03:24  Thursday   \n",
       "1        positive              0      0  2025-06-05    21:51:17  Thursday   \n",
       "2         neutral              0      1  2025-06-05    21:28:36  Thursday   \n",
       "3        positive              0      1  2025-06-05    21:14:08  Thursday   \n",
       "4         neutral              1      1  2025-06-05    20:24:59  Thursday   \n",
       "\n",
       "  Month  Review_Length  Word_Count  \n",
       "0  June            280          48  \n",
       "1  June             68          13  \n",
       "2  June            154          34  \n",
       "3  June            240          44  \n",
       "4  June           1620         320  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('Vodaphone_review_dataset.csv')\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27bce308",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_df = df_new[df_new['Sentiment Label'].str.lower() != 'positive'].copy()\n",
    "\n",
    "praise_df = df_new[df_new['Sentiment Label'].str.lower() == 'positive'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e5c9f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab', download_dir='/home/codespace/nltk_data')\n",
    "nltk.download('stopwords', download_dir='/home/codespace/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f1bf84",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\deela/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\deela\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\corpus\\util.py:84\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     root = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\deela/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\deela\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Preprocessing text\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m stop_words = \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m(\u001b[33m'\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreprocess\u001b[39m(text):\n\u001b[32m      5\u001b[39m     tokens = word_tokenize(text.lower())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\corpus\\util.py:120\u001b[39m, in \u001b[36mLazyCorpusLoader.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attr == \u001b[33m\"\u001b[39m\u001b[33m__bases__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLazyCorpusLoader object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[33m__bases__\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\corpus\\util.py:86\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     84\u001b[39m             root = nltk.data.find(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.subdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[32m     89\u001b[39m corpus = \u001b[38;5;28mself\u001b[39m.__reader_cls(root, *\u001b[38;5;28mself\u001b[39m.__args, **\u001b[38;5;28mself\u001b[39m.__kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\corpus\\util.py:81\u001b[39m, in \u001b[36mLazyCorpusLoader.__load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         root = \u001b[43mnltk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\deela/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\deela\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "complaints_df['tokens'] = complaints_df['Clean_Review'].apply(\n",
    "    lambda x: preprocess(x) if pd.notnull(x) else []\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary and corpus\n",
    "dictionary = corpora.Dictionary(complaints_df['tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in complaints_df['tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33577a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model (start with 5 topics)\n",
    "\n",
    "lda_model = gensim.models.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=5,\n",
    "    passes=10,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587427e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.010*\"router\" + 0.008*\"wifi\" + 0.007*\"vodafone\" + 0.006*\"fibre\" + 0.005*\"would\" + 0.004*\"still\" + 0.004*\"vodaphone\" + 0.004*\"like\" + 0.004*\"devices\" + 0.004*\"days\"\n",
      "Topic 2: 0.054*\"helpful\" + 0.016*\"vodafone\" + 0.014*\"staff\" + 0.013*\"service\" + 0.012*\"store\" + 0.012*\"extremely\" + 0.010*\"really\" + 0.009*\"phone\" + 0.008*\"professional\" + 0.008*\"thank\"\n",
      "Topic 3: 0.038*\"helpful\" + 0.029*\"phone\" + 0.021*\"new\" + 0.017*\"store\" + 0.017*\"helped\" + 0.013*\"thank\" + 0.013*\"sorted\" + 0.012*\"sim\" + 0.011*\"really\" + 0.010*\"everything\"\n",
      "Topic 4: 0.030*\"vodafone\" + 0.013*\"service\" + 0.011*\"would\" + 0.010*\"broadband\" + 0.008*\"customer\" + 0.006*\"internet\" + 0.005*\"time\" + 0.005*\"days\" + 0.005*\"issue\" + 0.004*\"even\"\n",
      "Topic 5: 0.016*\"vodafone\" + 0.014*\"phone\" + 0.012*\"contract\" + 0.012*\"service\" + 0.011*\"get\" + 0.011*\"customer\" + 0.008*\"told\" + 0.008*\"broadband\" + 0.008*\"call\" + 0.007*\"new\"\n"
     ]
    }
   ],
   "source": [
    "# Displaying the topics found by the LDA model\n",
    "\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for idx, topic in topics:\n",
    "    print(f\"Topic {idx+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the dominant topic for each document\n",
    "\n",
    "def get_topic(doc):\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    topic_probs = lda_model.get_document_topics(bow)\n",
    "    dominant_topic = max(topic_probs, key=lambda x: x[1])[0]\n",
    "    return dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe70d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_df['Topic'] = complaints_df['tokens'].apply(get_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6529ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Clean_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment Label</th>\n",
       "      <th>Churn_Keyword</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Review_Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trying to buy broadband through Uswitch, then ...</td>\n",
       "      <td>Alfie Calas</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 22:03:24+00:00</td>\n",
       "      <td>trying to buy broadband through uswitch then h...</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>22:03:24</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>280</td>\n",
       "      <td>48</td>\n",
       "      <td>[trying, buy, broadband, uswitch, multiple, er...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>One of the worst , if not the worst when it co...</td>\n",
       "      <td>Vlad Ureche</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 21:28:36+00:00</td>\n",
       "      <td>one of the worst if not the worst when it come...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>21:28:36</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>154</td>\n",
       "      <td>34</td>\n",
       "      <td>[one, worst, worst, comes, signal, get, n, mes...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Held to ransom by a ‘reputable’ company. Purch...</td>\n",
       "      <td>Chloe</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 20:24:59+00:00</td>\n",
       "      <td>held to ransom by a reputable company purchase...</td>\n",
       "      <td>-0.003634</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>20:24:59</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>1620</td>\n",
       "      <td>320</td>\n",
       "      <td>[held, ransom, reputable, company, purchased, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Mohamed was brillant and fixed my phone within...</td>\n",
       "      <td>Romy Aitken</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 18:46:06+00:00</td>\n",
       "      <td>mohamed was brillant and fixed my phone within...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>18:46:06</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>97</td>\n",
       "      <td>18</td>\n",
       "      <td>[mohamed, brillant, fixed, phone, within, mins...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the complaint I submitted to Vodafone:...</td>\n",
       "      <td>Adriana Castorina</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 18:44:57+00:00</td>\n",
       "      <td>this is the complaint i submitted to vodafone ...</td>\n",
       "      <td>0.067885</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>18:44:57</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>1513</td>\n",
       "      <td>295</td>\n",
       "      <td>[complaint, submitted, vodafone, move, flat, o...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rating                                             Review  \\\n",
       "0        1  Trying to buy broadband through Uswitch, then ...   \n",
       "2        1  One of the worst , if not the worst when it co...   \n",
       "4        1  Held to ransom by a ‘reputable’ company. Purch...   \n",
       "12       5  Mohamed was brillant and fixed my phone within...   \n",
       "13       1  This is the complaint I submitted to Vodafone:...   \n",
       "\n",
       "                 Name Location                       Date  \\\n",
       "0         Alfie Calas       GB  2025-06-05 22:03:24+00:00   \n",
       "2         Vlad Ureche       GB  2025-06-05 21:28:36+00:00   \n",
       "4               Chloe       GB  2025-06-05 20:24:59+00:00   \n",
       "12        Romy Aitken       GB  2025-06-05 18:46:06+00:00   \n",
       "13  Adriana Castorina       GB  2025-06-05 18:44:57+00:00   \n",
       "\n",
       "                                         Clean_Review  Sentiment  \\\n",
       "0   trying to buy broadband through uswitch then h...  -0.020000   \n",
       "2   one of the worst if not the worst when it come...  -0.200000   \n",
       "4   held to ransom by a reputable company purchase...  -0.003634   \n",
       "12  mohamed was brillant and fixed my phone within...   0.100000   \n",
       "13  this is the complaint i submitted to vodafone ...   0.067885   \n",
       "\n",
       "   Sentiment Label  Churn_Keyword  Churn Review_Date Review_Time   Weekday  \\\n",
       "0          neutral              1      1  2025-06-05    22:03:24  Thursday   \n",
       "2          neutral              0      1  2025-06-05    21:28:36  Thursday   \n",
       "4          neutral              1      1  2025-06-05    20:24:59  Thursday   \n",
       "12         neutral              0      0  2025-06-05    18:46:06  Thursday   \n",
       "13         neutral              1      1  2025-06-05    18:44:57  Thursday   \n",
       "\n",
       "   Month  Review_Length  Word_Count  \\\n",
       "0   June            280          48   \n",
       "2   June            154          34   \n",
       "4   June           1620         320   \n",
       "12  June             97          18   \n",
       "13  June           1513         295   \n",
       "\n",
       "                                               tokens  Topic  \n",
       "0   [trying, buy, broadband, uswitch, multiple, er...      3  \n",
       "2   [one, worst, worst, comes, signal, get, n, mes...      4  \n",
       "4   [held, ransom, reputable, company, purchased, ...      4  \n",
       "12  [mohamed, brillant, fixed, phone, within, mins...      4  \n",
       "13  [complaint, submitted, vodafone, move, flat, o...      3  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d355fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Clean_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment Label</th>\n",
       "      <th>Churn_Keyword</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Review_Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review_Length</th>\n",
       "      <th>Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Sona did a great job either my trade in and co...</td>\n",
       "      <td>Julliette</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 21:51:17+00:00</td>\n",
       "      <td>sona did a great job either my trade in and co...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>21:51:17</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>How those people get 4.6 rate that’s a joke my...</td>\n",
       "      <td>Adam Farbotko</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 21:14:08+00:00</td>\n",
       "      <td>how those people get rate thats a joke my full...</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>21:14:08</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>240</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent customer service. Vinnie was very he...</td>\n",
       "      <td>Farida Ariori</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 20:05:30+00:00</td>\n",
       "      <td>excellent customer service vinnie was very hel...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>20:05:30</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent service from Rushabh! He explained e...</td>\n",
       "      <td>kawater alismaeel</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 19:52:59+00:00</td>\n",
       "      <td>excellent service from rushabh he explained ev...</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>19:52:59</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>250</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Steven listened then provided a number of opti...</td>\n",
       "      <td>Dylan Owen</td>\n",
       "      <td>GB</td>\n",
       "      <td>2025-06-05 19:43:30+00:00</td>\n",
       "      <td>steven listened then provided a number of opti...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>19:43:30</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>June</td>\n",
       "      <td>175</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                             Review  \\\n",
       "1       5  Sona did a great job either my trade in and co...   \n",
       "3       1  How those people get 4.6 rate that’s a joke my...   \n",
       "5       5  Excellent customer service. Vinnie was very he...   \n",
       "6       5  Excellent service from Rushabh! He explained e...   \n",
       "7       5  Steven listened then provided a number of opti...   \n",
       "\n",
       "                Name Location                       Date  \\\n",
       "1          Julliette       GB  2025-06-05 21:51:17+00:00   \n",
       "3      Adam Farbotko       GB  2025-06-05 21:14:08+00:00   \n",
       "5      Farida Ariori       GB  2025-06-05 20:05:30+00:00   \n",
       "6  kawater alismaeel       GB  2025-06-05 19:52:59+00:00   \n",
       "7         Dylan Owen       GB  2025-06-05 19:43:30+00:00   \n",
       "\n",
       "                                        Clean_Review  Sentiment  \\\n",
       "1  sona did a great job either my trade in and co...   0.700000   \n",
       "3  how those people get rate thats a joke my full...   0.275000   \n",
       "5  excellent customer service vinnie was very hel...   0.600000   \n",
       "6  excellent service from rushabh he explained ev...   0.433333   \n",
       "7  steven listened then provided a number of opti...   0.350000   \n",
       "\n",
       "  Sentiment Label  Churn_Keyword  Churn Review_Date Review_Time   Weekday  \\\n",
       "1        positive              0      0  2025-06-05    21:51:17  Thursday   \n",
       "3        positive              0      1  2025-06-05    21:14:08  Thursday   \n",
       "5        positive              0      0  2025-06-05    20:05:30  Thursday   \n",
       "6        positive              0      0  2025-06-05    19:52:59  Thursday   \n",
       "7        positive              0      0  2025-06-05    19:43:30  Thursday   \n",
       "\n",
       "  Month  Review_Length  Word_Count  \n",
       "1  June             68          13  \n",
       "3  June            240          44  \n",
       "5  June             62           9  \n",
       "6  June            250          42  \n",
       "7  June            175          30  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "praise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c5f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Trying to buy broadband through Uswitch, then ...\n",
       "1       Sona did a great job either my trade in and co...\n",
       "2       One of the worst , if not the worst when it co...\n",
       "3       How those people get 4.6 rate that’s a joke my...\n",
       "4       Held to ransom by a ‘reputable’ company. Purch...\n",
       "                              ...                        \n",
       "9974    absolutely awful, been with vodaphone for 4 mo...\n",
       "9975    Had a great experience- until we decided to mo...\n",
       "9976    Karan and Isaac were both amazing. Give them a...\n",
       "9977                          Thank you mani your amazing\n",
       "9978    16 Years of Loyalty, But the Last 1.5 Years Ha...\n",
       "Name: Review, Length: 9979, dtype: object"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining responses for each topic\n",
    "\n",
    "topic_intents = {\n",
    "    0: \"Router or WiFi Issue\",\n",
    "    1: \"Staff and Service Feedback\",\n",
    "    2: \"Phone or SIM Setup\",\n",
    "    3: \"Broadband or Internet Problem\",\n",
    "    4: \"Contract or Plan Concern\"\n",
    "}\n",
    "\n",
    "topic_responses = {\n",
    "    0: \"It seems you're having trouble with your router or WiFi. Let's work together to get that sorted quickly.\",\n",
    "    1: \"Thanks for your feedback on our staff and service. We’ll review your concerns with the relevant team.\",\n",
    "    2: \"Appreciate you sharing your experience—let’s make sure your new phone or SIM setup is working as expected.\",\n",
    "    3: \"We're sorry about the broadband or internet issues you've faced. We’re investigating and working to improve reliability.\",\n",
    "    4: \"It looks like there’s frustration with your contract or service plan. We’ll help clarify and resolve that for you.\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87214eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping topics to responses\n",
    "\n",
    "complaints_df['Response'] = complaints_df['Topic'].map(topic_responses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a244abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       We're sorry about the broadband or internet is...\n",
       "2       It looks like there’s frustration with your co...\n",
       "4       It looks like there’s frustration with your co...\n",
       "12      It looks like there’s frustration with your co...\n",
       "13      We're sorry about the broadband or internet is...\n",
       "                              ...                        \n",
       "9971    Thanks for your feedback on our staff and serv...\n",
       "9973    Appreciate you sharing your experience—let’s m...\n",
       "9974    It looks like there’s frustration with your co...\n",
       "9975    It looks like there’s frustration with your co...\n",
       "9978    It looks like there’s frustration with your co...\n",
       "Name: Response, Length: 3140, dtype: object"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_df.Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b825bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(text, complaints_df):\n",
    "    # Look up sentiment from the dataset\n",
    "    sentiment_row = complaints_df[complaints_df['Clean_Review'] == text]\n",
    "    \n",
    "    if not sentiment_row.empty:\n",
    "        sentiment = sentiment_row['Sentiment Label'].values[0].lower()\n",
    "    else:\n",
    "        sentiment = \"neutral\"  # fallback if not found\n",
    "\n",
    "    if sentiment == \"positive\":\n",
    "        return \"Thanks for your feedback! We're glad you're happy with our service 😊\"\n",
    "    else:\n",
    "        tokens = preprocess(text)\n",
    "        bow = dictionary.doc2bow(tokens)\n",
    "        topic_probs = lda_model.get_document_topics(bow)\n",
    "        dominant_topic = max(topic_probs, key=lambda x: x[1])[0]\n",
    "        return topic_responses.get(dominant_topic, \"Thank you for reaching out.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aeb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_review = complaints_df['Clean_Review'].sample(1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eab8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['really helpful in store thanks to leon']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07afef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response: Appreciate you sharing your experience—let’s make sure your new phone or SIM setup is working as expected.\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(sample_review[0], complaints_df)\n",
    "print(\"Generated Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa30b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save(\"lda_dictionary.dict\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "lda_model.save(\"lda_model.gensim\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20471f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
